name: Daily Data and Model Pipeline

on:
  schedule:
    # Runs at 00:00 UTC (midnight) every day
    # Adjust as needed; '0 0 * * *' is midnight UTC
    - cron: '0 0 * * *'
  workflow_dispatch:
    # Adds a button in the "Actions" tab to run this manually

jobs:
  build-data-and-train:
    runs-on: ubuntu-latest
    
    steps:
      - name: 1. Check out repository
        uses: actions/checkout@v4

      - name: 2. Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10' # Or your preferred version

      - name: 3. Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas numpy scikit-learn xgboost joblib

      # --- DATA GENERATION ---
      - name: 4. Run data generation script
        run: python generate_data.py # Creates Unified_Weather_Dataset_Latest.json

      - name: 5. Commit and push the new dataset
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add Unified_Weather_Dataset_Latest.json
          # Check if there are changes to commit
          if ! git diff --staged --quiet; then
            git commit -m "DATA: Update daily weather data"
            git push
          else
            echo "No data changes to commit."
          fi

      # --- HASH AND SCRIPT UPDATE ---
      - name: 6. Calculate new hash and update script
        run: |
          # Calculate the new hash from the file we just made
          NEW_HASH=$(sha256sum Unified_Weather_Dataset_Latest.json | cut -d ' ' -f 1)
          
          echo "New hash is $NEW_HASH"
          
          # Use 'sed' (a Linux command) to find and replace the hash in run_pipeline.py
          # This command finds the line starting with "OFFICIAL_DATASET_HASH =" and replaces the whole line
          sed -i "s/^OFFICIAL_DATASET_HASH = \".*\"/OFFICIAL_DATASET_HASH = \"$NEW_HASH\"/" run_pipeline.py

      - name: 7. Commit and push the hash update
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add run_pipeline.py
          # Check if there are changes to commit
          if ! git diff --staged --quiet; then
            git commit -m "CHORE: Update data integrity hash"
            git push
          else
            echo "No hash changes to commit."
          fi

      # --- MODEL TRAINING ---
      - name: 8. Run the main pipeline (Check & Train)
        run: python run_pipeline.py # This will now pass the hash check

      - name: 9. Commit and push new models and forecast
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          # Add all .joblib (models, scalers) and the forecast JSON
          git add *.joblib
          git add forecast_*.json
          # Check if there are changes to commit
          if ! git diff --staged --quiet; then
            git commit -m "MODEL: Update models, scalers, and forecast"
            git push
          else
            echo "No new models or forecasts to commit."
          fi
